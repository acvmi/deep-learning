{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Concepts Recap with Keras"
      ],
      "metadata": {
        "id": "Or9Sjh-DzQDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Building Blocks of CNN:\n",
        "\t1. Convolutional Layers - filters, feature maps, pooling layers\n",
        "\t2. Pooling Layers \n",
        "\t3. Fully-Connected Layers \n",
        "\n",
        "Convolutional Neural Networks Best Practices\n",
        "With the building blocks for a convolutional neural network and how the layers \n",
        "work together, we can review best practices to consider when applying them.\n",
        "\n",
        "\t- Input Receptive Field Dimensions: The default is 2D for images, but could be \n",
        "  1D such as for words in a sentence or 3D for video that adds a time dimension.\n",
        "\n",
        "\t- Receptive Field Size: The patch should be as small as possible, but large \n",
        "  enough to see features in the input data. It is common to use 3 × 3 on small \n",
        "  images and 5 × 5 or 7 × 7 and more on larger image sizes.\n",
        "\n",
        "\t- Stride Width: Use the default stride of 1. It is easy to understand and you \n",
        "  don’t need padding to handle the receptive field falling off the edge of your \n",
        "  images. This could be increased to 2 or larger for larger images.\n",
        "\n",
        "\t- Number of Filters: Filters are the feature detectors. Generally fewer filters \n",
        "  are used at the input layer and increasingly more filters used at deeper layers.\n",
        "\n",
        "\t- Padding: Set to zero and called zero padding when reading non-input data. \n",
        "  This is useful when you cannot or do not want to standardize input image sizes \n",
        "  or when you want to use receptive field and stride sizes that do not neatly \n",
        "  divide up the input image size.\n",
        "\n",
        "\t- Pooling: Pooling is a destructive or generalization process to reduce \n",
        "  overfitting. Receptive field size is almost always set to 2 × 2 with a stride \n",
        "  of 2 to discard 75% of the activations from the output of the previous layer.\n",
        "\n",
        "\t- Data Preparation: Consider standardizing input data, both the dimensions \n",
        "  of the images and pixel values.\n",
        "\n",
        "\t- Pattern Architecture: It is common to pattern the layers in your network \n",
        "  architecture. This might be one, two or some number of convolutional layers \n",
        "  followed by a pooling layer. This structure can then be repeated one or more \n",
        "  times. Finally, fully connected layers are often only used at the output end \n",
        "  and may be stacked one, two or more deep.\n",
        "  \n",
        "\t- Dropout: CNNs have a habit of overfitting, even with pooling layers. \n",
        "  Dropout should be used such as between fully connected layers and perhaps \n",
        "  after pooling layers.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ja_eM0cFzQUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handwritten Digit recognition"
      ],
      "metadata": {
        "id": "zCr21hQpzhTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Demonstration of capabilities of deep learning is the object recognition.\n",
        "The simple 'hello world' program with any programming language, for ML and DL,\n",
        "is the MNIST dataset for handwritten digit recognition.\n",
        "1. Develop a DL model near state-of-art performance for the MNIST dr task. Use\n",
        "   Python/Keras libraries \n",
        "2. Implement and evaluate the convolutional neural network \n",
        "3. Use GPU and not CPU to speed up the computation \n",
        "\n",
        "MNIST dataset is constructed fro scanned images and opened source. The image of\n",
        "digits were taken from a variety of scanned documents, normalized and centered. \n",
        "Excellent dataset for evaluating models in order to allow developers to focus \n",
        "on ML snd not spent much time on data preparation. \n",
        "Each split is 28x28 - 784 pixels total. A standard split is used to evaluate and \n",
        "compare models, where 60,000 images are used to train a model and separate a set \n",
        "of 10,000 images used to test it. \n",
        "10 classes used to predict (0-9 digits), with results reported as prediction \n",
        "error with inverted calssification for accuracy \n",
        "Criteria:\n",
        "  - excellent results achieve a prediction error of less than 1%\n",
        "  - state-of-art results predition error of approx. 0.2% (achievable w/ CNN)\n",
        "\n",
        "Dataset as package in size of 15 megabytes \n",
        "~./keras/datasets/mnist.pkl.gz \n",
        "Download/load the dataset with keras functions \n",
        "\"\"\"\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\"\"\" plot 4 images as gray scale \"\"\" \n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "X_train.shape, y_train.shape, X_test.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "0tzjvrJfzhzV",
        "outputId": "9cd7de08-1165-4275-ffbb-58a697fbb28e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" baseline model with multilayer perceptrons \"\"\" \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.utils import np_utils \n",
        "\"\"\" load the data \"\"\" \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\"\"\" flatten 28x28 images to a 784 vector for each image \"\"\" \n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
        "\"\"\" normalize inputs from 0-255 to 0-1 \"\"\" \n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255 \n",
        "\"\"\" output is an integer from 0 to 9. this is a multiclass classification \n",
        "as such as best practice, use one hot encoding of the class values transforming\n",
        "the vector of class integers into a binary matrix. \n",
        "use built-in helper from keras np.utils.to.categorical() function \"\"\" \n",
        "\"\"\" one hot-encoding \"\"\" \n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\"\"\" baseline model, define and compile \"\"\" \n",
        "def baseline_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  return model \n",
        "\n",
        "\"\"\" multilayer perceptrons \n",
        "    visible layer (784 inputs) \n",
        "      |\n",
        "    hidden layer (784 inputs) \n",
        "      |\n",
        "    output layer (10 outputs/classes) \"\"\"\n",
        "\n",
        "\"\"\" build the model \"\"\" \n",
        "model = baseline_model()\n",
        "\"\"\" fit the model \"\"\" \n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, \n",
        "          batch_size=200, verbose=2)\n",
        "\"\"\" final evaluation \"\"\" \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('baseline error: % 2f%%' % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pyCcVlPzpe7",
        "outputId": "7b76dc91-7a10-490c-e8de-9a13c0582c84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 6s - loss: 0.2780 - accuracy: 0.9211 - val_loss: 0.1397 - val_accuracy: 0.9597 - 6s/epoch - 21ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 6s - loss: 0.1120 - accuracy: 0.9673 - val_loss: 0.0942 - val_accuracy: 0.9725 - 6s/epoch - 21ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 6s - loss: 0.0722 - accuracy: 0.9792 - val_loss: 0.0805 - val_accuracy: 0.9759 - 6s/epoch - 18ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 8s - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.0631 - val_accuracy: 0.9812 - 8s/epoch - 26ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 8s - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.0641 - val_accuracy: 0.9795 - 8s/epoch - 28ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 6s - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0623 - val_accuracy: 0.9807 - 6s/epoch - 21ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 5s - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.0593 - val_accuracy: 0.9819 - 5s/epoch - 17ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 6s - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0573 - val_accuracy: 0.9822 - 6s/epoch - 21ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 5s - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0626 - val_accuracy: 0.9811 - 5s/epoch - 17ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 6s - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0624 - val_accuracy: 0.9817 - 6s/epoch - 21ms/step\n",
            "baseline error:  1.830000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Convolutional Neural Network template/structure \"\"\"\n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import Flatten \n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils \n",
        "\"\"\" load the data \"\"\" \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\"\"\" flatten 28x28 images to a 784 vector for each image \"\"\" \n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "\"\"\" normalize inputs from 0-255 to 0-1 \"\"\" \n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255 \n",
        "\"\"\" one hot-encoding \"\"\" \n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\"\"\" CNN structure\n",
        "    visible layer (784 inputs = 1x28x28) \n",
        "    convolutional layer (32 maps, 5x5) \n",
        "    max pooling layer (4 (2x2)) \n",
        "    dropout layer (20%)\n",
        "    flatten layer \n",
        "    hidden layer (128 neurons)\n",
        "    output layer (10 outputs)\n",
        "\"\"\"\n",
        "\"\"\" CNN model, define and compile \"\"\" \n",
        "def baseline_model_cnn():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (5,5), input_shape=(28,28,1), activation='relu'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  return model \n",
        "model = baseline_model_cnn()\n",
        "\"\"\" fit the model \"\"\" \n",
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=10, \n",
        "          batch_size=200, verbose=2)\n",
        "\"\"\" final evaluation \"\"\" \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('CNN error: % 2f%%' % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaz0GmaVzc_E",
        "outputId": "e92d7bd6-cc12-476d-9668-dae2852627ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 49s - loss: 0.2393 - accuracy: 0.9318 - val_loss: 0.0796 - val_accuracy: 0.9752 - 49s/epoch - 163ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 44s - loss: 0.0734 - accuracy: 0.9782 - val_loss: 0.0469 - val_accuracy: 0.9841 - 44s/epoch - 146ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 41s - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.0441 - val_accuracy: 0.9860 - 41s/epoch - 136ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 39s - loss: 0.0404 - accuracy: 0.9875 - val_loss: 0.0345 - val_accuracy: 0.9883 - 39s/epoch - 130ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 44s - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0334 - val_accuracy: 0.9874 - 44s/epoch - 147ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 39s - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0319 - val_accuracy: 0.9886 - 39s/epoch - 130ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 35s - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0314 - val_accuracy: 0.9890 - 35s/epoch - 118ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 37s - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0293 - val_accuracy: 0.9895 - 37s/epoch - 123ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 35s - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0350 - val_accuracy: 0.9880 - 35s/epoch - 117ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 35s - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0375 - val_accuracy: 0.9891 - 35s/epoch - 118ms/step\n",
            "CNN error:  1.090002%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Larger CNN for MNIST"
      ],
      "metadata": {
        "id": "U4WHtAqg0eas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" CNN structure (architecture)\n",
        "    visible layer (784 inputs = 1x28x28) \n",
        "    convolutional layer (30 maps, 5x5) \n",
        "    max pooling layer (4 (2x2)) \n",
        "    convolutional layer (15 maps, 3x3) \n",
        "    max pooling layer (4 (2x2)) \n",
        "    dropout layer (20%)\n",
        "    hidden layer (128 neurons)\n",
        "    hidden layer (50 neurons)\n",
        "    output layer (10 outputs)\n",
        "\"\"\"\n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import Flatten \n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils \n",
        "\"\"\" load the data \"\"\" \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\"\"\" flatten 28x28 images to a 784 vector for each image \"\"\" \n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "\"\"\" normalize inputs from 0-255 to 0-1 \"\"\" \n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255 \n",
        "\"\"\" one hot-encoding \"\"\" \n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\"\"\" CNN model, define and compile \"\"\" \n",
        "def large_model_cnn():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(30, (5,5), input_shape=(28,28,1), activation='relu'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Conv2D(15, (3,3), activation='relu')) \n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  return model \n",
        "model = large_model_cnn()\n",
        "\"\"\" fit the model \"\"\" \n",
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=10, \n",
        "          batch_size=200, verbose=2)\n",
        "\"\"\" final evaluation \"\"\" \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Large CNN error: % 2f%%' % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmwZG3LzzuvA",
        "outputId": "0788f93a-1681-4b9b-a54d-bc940a772a48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 44s - loss: 0.3710 - accuracy: 0.8867 - val_loss: 0.0798 - val_accuracy: 0.9747 - 44s/epoch - 146ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 39s - loss: 0.0932 - accuracy: 0.9718 - val_loss: 0.0486 - val_accuracy: 0.9850 - 39s/epoch - 131ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 40s - loss: 0.0679 - accuracy: 0.9787 - val_loss: 0.0447 - val_accuracy: 0.9857 - 40s/epoch - 135ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 42s - loss: 0.0571 - accuracy: 0.9820 - val_loss: 0.0376 - val_accuracy: 0.9871 - 42s/epoch - 140ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 42s - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.0303 - val_accuracy: 0.9895 - 42s/epoch - 140ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 40s - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.0289 - val_accuracy: 0.9916 - 40s/epoch - 135ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 40s - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0272 - val_accuracy: 0.9908 - 40s/epoch - 133ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 39s - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0257 - val_accuracy: 0.9917 - 39s/epoch - 131ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 42s - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0270 - val_accuracy: 0.9903 - 42s/epoch - 139ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 40s - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0230 - val_accuracy: 0.9926 - 40s/epoch - 133ms/step\n",
            "Large CNN error:  0.739998%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### simple CNN model for CIFAR-10"
      ],
      "metadata": {
        "id": "20FRa3b70YWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" CNN structure \n",
        "  1. CNN input layer, 32 feature maps with size 3x3, a rectifier activation Fn,\n",
        "     and a weight constraint of max norm set to 3 \n",
        "  2. Dropout set to 20% \n",
        "  3. CNN layer, 32 feature maps with size of 3x3, a rectifier activation Fn,\n",
        "     and a weight constraint of max norm set to 3 \n",
        "  4. Max Pool layer with size 2x2 \n",
        "  5. Flatten layer\n",
        "  6. Fully connected layer with 512 units and rectifier activation Fn\n",
        "  7. Dropout set to 50% \n",
        "  8. Fully connected output layer with 10 units and softmax activation function\n",
        "A logarithmic loss function is used with stochastic grdient descent configured\n",
        "with a large momentum and weight decay, starting with learning rate (lr) of 0.01\n",
        "\n",
        "    Visible Layer (3x32x32)\n",
        "    Convolutional Layer (32 maps, 3x3)\n",
        "    Dropout Layer (20%)\n",
        "    Convolutional Layer(32 aps 3x3)\n",
        "    Max Pooling Layer (2x2)\n",
        "    Hidden Layer (512 neurons)\n",
        "    Dropout Layer (20%)\n",
        "    Output Layer (10 outputs)\n",
        "\n",
        "\"\"\"\n",
        "from keras.datasets import cifar10 \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import Flatten \n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD \n",
        "from keras.layers.convolutional import Conv2D \n",
        "from keras.layers.convolutional import MaxPooling2D \n",
        "from keras.utils import np_utils\n",
        "\"\"\" load data \"\"\"\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\"\"\" normalize inputs from 0-255 to 0.0-1.0 \"\"\" \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n",
        "\"\"\" one hot encode outputs \"\"\" \n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\"\"\" create the CNN model \"\"\" \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), padding='same', \n",
        "          activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3,3), padding='same', \n",
        "          activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\"\"\" compile model \"\"\" \n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\"\"\" fit the model \"\"\" \n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "          epochs=epochs, batch_size=32)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: % 2f%%' % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5JC4ykIz2JL",
        "outputId": "54fd3607-79cf-4938-c3a1-3d0fec7402c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,210,090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 295s 188ms/step - loss: 1.6920 - accuracy: 0.3876 - val_loss: 1.3968 - val_accuracy: 0.4923\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 284s 182ms/step - loss: 1.3480 - accuracy: 0.5125 - val_loss: 1.2070 - val_accuracy: 0.5685\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 274s 175ms/step - loss: 1.1852 - accuracy: 0.5775 - val_loss: 1.1050 - val_accuracy: 0.6057\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 272s 174ms/step - loss: 1.0543 - accuracy: 0.6270 - val_loss: 1.0461 - val_accuracy: 0.6298\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 286s 183ms/step - loss: 0.9516 - accuracy: 0.6615 - val_loss: 0.9955 - val_accuracy: 0.6526\n",
            "Epoch 6/25\n",
            "1221/1563 [======================>.......] - ETA: 57s - loss: 0.8589 - accuracy: 0.6953"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extensions to improve the model performance"
      ],
      "metadata": {
        "id": "Bq4IvXfG0rlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" example with Larger CNN for CIFAR-10 \n",
        "\n",
        "Larger/Deeper CNN means adding additional round of convolutions with large \n",
        "feature maps, using same pattern of Convolutional, Dropout, Convolutional Max \n",
        "and Pooling layers. Repeat the pattern 3 times with 32, 64, and 128 feature maps.\n",
        "The effect will be an increasing number of feature maps with smaller size given \n",
        "the max pooling layers. An additional and larger Dense layer will be used as the \n",
        "output end of the networkin an attempt to better translate the large number \n",
        "feature maps to class values.\n",
        "Network architecture as follows: \n",
        "  1. Convolutional input layer, 32 feature maps with a size of 3x3 and a \n",
        "     rectifier activation function\n",
        "  2. Dropout layer at 20% \n",
        "  3. Convolutional layer, 32 feature maps with a size of 3x3 and a rectifier \n",
        "     activation function\n",
        "  4. Max pool layer with size 2x2 \n",
        "  5. Convolutional layer, 64 feature maps with a size of 3x3 and a rectifier \n",
        "     activation function\n",
        "  6. Dropout layer at 20% \n",
        "  7. Convolutional layer, 64 feature maps with a size of 3x3 and a rectifier \n",
        "     activation function\n",
        "  8. Max pool layer with size 2x2 \n",
        "  9. Convolutional layer, 128 feature maps with a size of 3x3 and a rectifier \n",
        "     activation function\n",
        "  10. Dropout layer at 20% \n",
        "  11. Convolutional layer, 128 feature maps with a size of 3x3 and a rectifier \n",
        "     activation function  \n",
        "  12. Max pool layer with size 2x2 \n",
        "  13. Flatten layer at 20% \n",
        "  14. Dropout layer at 20%\n",
        "  15. Fully connected layer with 1024 units and a rectifier activation function\n",
        "  16. Dropput layer at 20%\n",
        "  17. Fully connected layer with 512 units and a rectifier activation function \n",
        "  18. Dropout layer at 20% \n",
        "  19. Fully connected output layer with 10 units and a softmax activation function\n",
        "Fit and evaluate the model using same procedure as above, with smae epochs, and\n",
        "a larger batch size of 64. \n",
        "\n",
        "\"\"\"\n",
        "from keras.datasets import cifar10 \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import Flatten \n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD \n",
        "from keras.layers.convolutional import Conv2D \n",
        "from keras.layers.convolutional import MaxPooling2D \n",
        "from keras.utils import np_utils\n",
        "\"\"\" load data \"\"\"\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\"\"\" normalize inputs from 0-255 to 0.0-1.0 \"\"\" \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n",
        "\"\"\" one hot encode outputs \"\"\" \n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\"\"\" create the CNN model \"\"\" \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), \n",
        "                 padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\"\"\" compile model \"\"\" \n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\"\"\" fit the model \"\"\" \n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "          epochs=epochs, batch_size=64)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: % 2f%%' % (scores[1]*100))\n",
        "\n",
        "\"\"\" Accuracy improved by 10 points \"\"\" "
      ],
      "metadata": {
        "id": "9pdyd7W80tAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" extend upon the model and improve the performance \n",
        "\n",
        "1. Train for more epochs - it is common for CNNs to use hundred or thousands of \n",
        "   epochs. Performance gains can be achieved by significantly raising the number \n",
        "   of training epochs.\n",
        "2. Image data augmentation - the objects in the image vary in their position. \n",
        "   Use data augmentation to boost model performance. Methods such as \n",
        "   standardization and random shifts and horizontal image flips may be beneficial.\n",
        "3. Deeper network topology - larger netorks could be designed for this problem. \n",
        "   It involves more feature maps in the input and less aggresive pooling. \n",
        "   Standard CNN topologies (as above) are useful for adoption and evaluation\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a79iMIvL1Mzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

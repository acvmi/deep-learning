{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network \n",
        "\n",
        "**Concepts only - Implementation without using any framework or libraries**\n",
        "```\n",
        "- Forward Softmax, Backward Softmax, Backward Relu, Forward Convolution, \n",
        "- Backward Convolution, Forward Max Pool Layering, Backward Max Pool Layering,\n",
        "- Forward Cross Entropy Loss, Forward Linear, Backward Linear, \n",
        "- Forward Propagation, Backward Propagation, Forward Prop Batch \n",
        "- Gradient Descent Batch, Train/Test, Compute Accuracy and Run-through\n",
        "```"
      ],
      "metadata": {
        "id": "QOiE2u6YO65Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import functools"
      ],
      "metadata": {
        "id": "OBLW723wqdxJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_softmax(x):\n",
        "  \"\"\"\n",
        "  Compute softmax function for a single example\n",
        "  The input x, 1d float numpy has shape that is the size of number of classes \n",
        "  Returns 1d numpy float that has the softmax results of shape number of classes\n",
        "  \"\"\"\n",
        "  x = x - np.max(x, axis=0)\n",
        "  exp_x = np.exp(x)\n",
        "  softmax_ = exp_x / np.sum(exp_x, axis=0)\n",
        "  \n",
        "  return softmax_"
      ],
      "metadata": {
        "id": "dfWW8srkqd3h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_softmax(x, gradient_of_outputs): \n",
        "  \"\"\"\n",
        "  Compute the gradient of the loss with respect to x\n",
        "  gradient-output is the gradient of the loss with respect to the outputs \n",
        "  of softmax, and 1d numpy float array of shape number of classes \n",
        "  \"\"\"\n",
        "  probabilities = forward_softmax(x)\n",
        "  gradient_of_x = np.zeros(x.shape)\n",
        "\n",
        "  for i in range(gradient_of_outputs.shape[0]):\n",
        "    for j in range(gradient_of_outputs.shape[0]):\n",
        "      if i == j :\n",
        "        gradient_of_x[i] += \\\n",
        "            probabilities[i] * (1- probabilities[j])*gradient_of_outputs[j]      \n",
        "      else:\n",
        "        gradient_of_x[i] += \\\n",
        "           -probabilities[i] * probabilities[j] * gradient_of_outputs[j]\n",
        "  \n",
        "  return gradient_of_x"
      ],
      "metadata": {
        "id": "UTepS1XhrkPA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_relu(x):\n",
        "  \"\"\"\n",
        "  Compute the Relu function for the input x \n",
        "  Returns numpy float array containing relu results \n",
        "  \"\"\"\n",
        "  x[x<=0] = 0 \n",
        "\n",
        "  return x "
      ],
      "metadata": {
        "id": "y7CF258CtlQa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_relu(x, gradient_of_outputs):\n",
        "  \"\"\" \n",
        "  Compute the gradient of the loss with respect to x \n",
        "  x of arbitrary shape \n",
        "  gradient-of-outputs of the same shape of x with the gradient of the loss with\n",
        "  respect to the output of Relu \n",
        "  \"\"\"\n",
        "  x[x<=0] = 0 \n",
        "  x[x>0] = 1 \n",
        "  r_ = x * gradient_of_outputs\n",
        "\n",
        "  return r_"
      ],
      "metadata": {
        "id": "wqoIIT7IuDqV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Define Constants \"\"\" \n",
        "CONVOLUTION_SIZE = 4\n",
        "CONVOLUTION_FILTERS = 2 \n",
        "MAX_POOL_SIZE = 5 "
      ],
      "metadata": {
        "id": "g4uWd0FqwHVR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_initial_params(): \n",
        "  \"\"\" \n",
        "  A function to initialize model parameters \n",
        "  A dictionary mapping of parameter names to numpy arrays containing the inital\n",
        "  values for those parameters. \n",
        "    - W1 the weight matrix for the hidden layer of size input_size x num_hidden\n",
        "    - b1 is the bias vector for the hidden layer of size num_hidden \n",
        "    - W2 the weight matrix for the output layers of size num_hidden x num_output \n",
        "    - b2 the vector for the output layer of size num_output \n",
        "    Weight matrices are initialized with random normal distribution \n",
        "    The mean of the distribution should be 0 \n",
        "    The variance of that distribution should be 1/sqrt(n) where n is the number \n",
        "    of neurons that feed into the output for that layer \n",
        "    Bias vectors should be initialized with zero \n",
        "  \"\"\"\n",
        "  dimension_after_convolution = 28 - CONVOLUTION_SIZE + 1 \n",
        "  dimension_with_maxpooling = dimension_after_convolution // MAX_POOL_SIZE\n",
        "  num_hidden = \\\n",
        "    dimension_with_maxpooling * dimension_with_maxpooling * CONVOLUTION_FILTERS\n",
        "  \n",
        "  params = {\n",
        "      'W1': np.random.normal(\n",
        "              size=(CONVOLUTION_FILTERS, 1, CONVOLUTION_SIZE, CONVOLUTION_SIZE), \n",
        "              scale=1/math.sqrt(CONVOLUTION_SIZE*CONVOLUTION_SIZE)), \n",
        "      'b1': np.zeros(CONVOLUTION_FILTERS),\n",
        "      'W2': np.random.normal(size=(num_hidden,10),scale=1/math.sqrt(num_hidden)),\n",
        "      'b2': np.zeros(10)\n",
        "  } \n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "KPqH1vd_vAIf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_convolution(conv_layer_Weights, conv_layer_bias, conv_layer_data):\n",
        "  \"\"\"\n",
        "  Compute the output from a convolutional layer \n",
        "  convolutional_layer_Weights of shape:\n",
        "    number-of-input-channels, convolution width and height \n",
        "  convolutional_layer_bias of shape:\n",
        "    number-of-output-channels\n",
        "  convolutional_layer_data of shape:\n",
        "    number-of-input-channels, width and height\n",
        "  convolutional_layer_output, result of convolution, of shape:\n",
        "    number-of-output-channels, width - convolution width +1, \n",
        "                               height - convolution height +1\n",
        "  \"\"\"\n",
        "  conv_channels, _, conv_width, conv_height = conv_layer_Weights.shape\n",
        "  input_channels, input_width, input_height = conv_layer_data.shape \n",
        "  conv_output = np.zeros(\n",
        "      (conv_channels, input_width-conv_width +1, input_height-conv_height +1))\n",
        "  \n",
        "  for x in range(input_width - conv_width + 1):\n",
        "    for y in range(input_height - conv_height + 1):\n",
        "      for output_channel in range(conv_channels):\n",
        "        # convolution_output = np.sum(np.multiply(Data, Weights) + bias)\n",
        "        conv_output[output_channel, x, y] = np.sum(np.multiply(\n",
        "            conv_layer_data[:, x:(x + conv_width), y:(y + conv_height)], \n",
        "            conv_layer_Weights[output_channel,:,:,:])) + conv_layer_bias[output_channel]\n",
        "  \n",
        "  return conv_output"
      ],
      "metadata": {
        "id": "cA9XKPOvyy8l"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_convolution(conv_layer_Weights, conv_layer_bias, conv_layer_data,\n",
        "                         output_gradient):\n",
        "  \"\"\" \n",
        "  Compute gradient of the loss with respect to the parameters of the convolution\n",
        "  In forward-convolution, output-gradient is the gradient of the loss with \n",
        "  respect to the output of the convolution\n",
        "  Returns a tuple of three gradients \n",
        "    - the gradient of the loss with respect to the convolution weights\n",
        "    - the gradient of the loss with respect to the convolution bias \n",
        "    - the gradient of the loss with respect to the inputput data \n",
        "  \"\"\" \n",
        "  conv_channels, _, conv_width, conv_height = conv_layer_Weights.shape \n",
        "  input_channels, input_width, input_height = conv_layer_data.shape \n",
        "  bias_gradient = np.zeros(conv_layer_bias.shape)\n",
        "  weights_gradient = np.zeros(conv_layer_Weights.shape)\n",
        "  data_gradient = np.zeros(conv_layer_data.shape)\n",
        "\n",
        "  for x in range(input_width - conv_width + 1):\n",
        "    for y in range(input_height - conv_height +1):\n",
        "      for output_channel in range(conv_channels):\n",
        "        bias_gradient[output_channel] += output_gradient[output_channel, x, y]\n",
        "        weights_gradient[output_channel, :, :, :] += \\\n",
        "          conv_layer_data[:, x:(x + conv_width), y:(y + conv_height)] * \\\n",
        "          output_gradient[output_channel, x, y]\n",
        "        data_gradient[:, x:(x + conv_width), y:(y + conv_height)] += \\\n",
        "          conv_layer_Weights[output_channel, :, :, :] * \\\n",
        "          output_gradient[output_channel, x, y]\n",
        "  \n",
        "  return weights_gradient, bias_gradient, data_gradient "
      ],
      "metadata": {
        "id": "_7zJkzxTDsc3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_max_pool(data, pool_width, pool_height): \n",
        "  \"\"\" \n",
        "  Compute the output from a max pooling layer given the data and pool dimensions\n",
        "  The stride length should be equal to the pool size \n",
        "  data is of shape (number-of-channels, width, height)\n",
        "  The output should be the result of the max pooling layer and should be of size:\n",
        "    (number-of-channels, width // pool_width, height // pool_height)\n",
        "  Returns the result of the max pooling layer \n",
        "  \"\"\"\n",
        "  input_channels, input_width, input_height = data.shape\n",
        "  output = np.zeros((input_channels, input_width // pool_width, \n",
        "                     input_height // pool_height))\n",
        "  \n",
        "  for x in range(0, input_width, pool_width):\n",
        "    for y in range(0, input_height, pool_height):\n",
        "      output[:, x // pool_width, y // pool_height] = np.amax(\n",
        "          data[:, x:(x + pool_width), y:(y + pool_height)], axis=(1,2))\n",
        "\n",
        "  return output "
      ],
      "metadata": {
        "id": "sbJuWQ9xSv_F"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_max_pool(data, pool_width, pool_height, output_gradient): \n",
        "  \"\"\" \n",
        "  Compute the gradient of the loss with respect to data in the max pool layer \n",
        "  data is of shape [number-of-channels, width, height] \n",
        "  output-gradient is the gradient of the loss with respect to the output of the\n",
        "  backward max pool layer, and is of shape \n",
        "    [number-of-channels, width//pool_width, height/pool_height]]\n",
        "  Returns the gradient of the loss with respectto the data, of same shape \n",
        "  \"\"\"\n",
        "  input_channels, input_width, input_height = data.shape\n",
        "  data_gradient = np.zeros(data.shape)\n",
        "\n",
        "  for x in range(0, input_width, pool_width):\n",
        "    for y in range(0, input_height, pool_height):\n",
        "      for channel in range(input_channels):\n",
        "        max_index = np.argmax( \n",
        "            data[channel, x:(x + pool_width), y:(y + pool_height)])\n",
        "        i, j = np.unravel_index(max_index, (pool_width, pool_height))\n",
        "        data_gradient[channel, x +i, y +j] += output_gradient[\n",
        "            channel, x // pool_width, y // pool_height]\n",
        "  \n",
        "  return data_gradient "
      ],
      "metadata": {
        "id": "mwqBpa7YSwC9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_cross_entropy_loss(probabilities, labels): \n",
        "  \"\"\" \n",
        "  Compute the output from a cross entropy loss layer given \n",
        "  the probabilities and labels, of shape number of classes\n",
        "  Return the output as a scalar, the result of the log loss layer \n",
        "  \"\"\"\n",
        "  result = 0 \n",
        "  for i, label in enumerate(labels):\n",
        "    if label == 1: \n",
        "      result += -np.log(probabilities[i])\n",
        "  return result "
      ],
      "metadata": {
        "id": "_ValipFGSwIn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_cross_entropy_loss(probabilities, labels): \n",
        "  \"\"\" \n",
        "  Compute the output from a cross entropy loss with respect to the probsbilities\n",
        "  the probabilities and labels, of shape number of classes\n",
        "  Return the gradient of the loss with respect to the probabilities \n",
        "  \"\"\"\n",
        "  gradient_probabilities = np.zeros(probabilities.shape)\n",
        "  for i, label in enumerate(labels):\n",
        "    if label == 1: \n",
        "      gradient_probabilities[i] = -1 / probabilities[i]\n",
        "  return gradient_probabilities"
      ],
      "metadata": {
        "id": "DnDnB-zLSwMi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_linear(weights, bias, data):\n",
        "  \"\"\" \n",
        "  Compute the output from a linear layer with the given weights, bias and data \n",
        "  weights is shape (input-number-of-features, output-number-of-features)\n",
        "  bias is of shape (output-number-of-features)\n",
        "  data is of shape (input number of features)\n",
        "  Returns the result of the linear layer, of shape output-number-pf-features \n",
        "  \"\"\"\n",
        "  s = data.dot(weights) + bias \n",
        "  return s"
      ],
      "metadata": {
        "id": "Kbdh6AzQTb4d"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_linear(weights, bias, data, output_gradient):\n",
        "  \"\"\" \n",
        "  Compute the gradients of the loss with respect to the params of a linear layer\n",
        "  Return a tuple of three elements:\n",
        "    - the gradient of the loss with respect to the weights \n",
        "    - the gradient of the loss with respect to the bias \n",
        "    - the gradient of the loss with respect to the data  \n",
        "  \"\"\" \n",
        "  bias_gradient = output_gradient \n",
        "  weights_gradient = np.outer(data, output_gradient)\n",
        "  data_gradient = np.dot(weights, output_gradient)\n",
        "\n",
        "  return weights_gradient, bias_gradient, data_gradient "
      ],
      "metadata": {
        "id": "HhGrSgIjSwQK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(data, labels, params):\n",
        "  \"\"\" \n",
        "  Implement the forward layer given the data, labels, and parameters \n",
        "  data: numpy 1d array of shape 1x28x28 \n",
        "  labels: numpy 1d array containing labels of shape 10 \n",
        "  params: dictionary mapping parameters to numpy arrays with parameters \n",
        "    - W1, b1, W2, and b2 \n",
        "    - W1 and b1 represent the weights and bias for the hidden layer of network \n",
        "    - W2 and b2 represent the weights and bias for the output layer of network \n",
        "  Returns a tuple containing\n",
        "    - numpy array, utput after softmax of output layer \n",
        "    - average loss for these data elements \n",
        "  \"\"\" \n",
        "  W1 = params['W1'] \n",
        "  b1 = params['b1']\n",
        "  W2 = params['W2']\n",
        "  b2 = params['b2']\n",
        "\n",
        "  first_convolution = forward_convolution(W1, b1, data)\n",
        "  first_max_pool = forward_max_pool(first_convolution, MAX_POOL_SIZE, MAX_POOL_SIZE)\n",
        "  first_after_relu = forward_relu(first_max_pool)\n",
        "\n",
        "  flattened = np.reshape(first_after_relu, (-1))\n",
        "  logits = forward_linear(W2, b2, flattened)\n",
        "\n",
        "  y = forward_softmax(logits)\n",
        "  cost = forward_cross_entropy_loss(y, labels)\n",
        "\n",
        "  return y, cost "
      ],
      "metadata": {
        "id": "ej7-dyy6Swbp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_prop(data, labels, params):\n",
        "  \"\"\" \n",
        "  Compute the backward propagation gradient step for a neural network \n",
        "  data: numpy array of the input for a single example \n",
        "  labels: 1d numpy array of labels for a single example \n",
        "  params: dictionary mapping parameter nmes to numpy arrays with the params \n",
        "    - W1, b1, W2, b2 \n",
        "    - W1 and b1 represent the weights and bias for the convolution layer \n",
        "    - W2 and b2 represent the weights and bias for the output layer of network \n",
        "  Returns dictionary of strings to numpy arrays where each key represents the \n",
        "  name of a weight, and the values represent the gradient of the loss with \n",
        "  respect to that weight \n",
        "    - W1, W2, b1 and b2 \n",
        "  \"\"\"\n",
        "  W1 = params['W1'] \n",
        "  b1 = params['b1'] \n",
        "  W2 = params['W2'] \n",
        "  b2 = params['b2']  \n",
        "\n",
        "  first_convolution = forward_convolution(W1, b1, data)\n",
        "  first_max_pool = forward_max_pool(\n",
        "                        first_convolution, MAX_POOL_SIZE, MAX_POOL_SIZE)\n",
        "  first_after_relu = forward_relu(first_max_pool)\n",
        "\n",
        "  flattened = np.reshape(first_after_relu, (-1))\n",
        "  logits = forward_linear(W2, b2, flattened)\n",
        "  y = forward_softmax(logits) \n",
        "  cost = forward_cross_entropy_loss(y, labels)\n",
        "  y_gradient = backward_cross_entropy_loss(y, labels)\n",
        "  logits_gradient = backward_softmax(logits, y_gradient)\n",
        "\n",
        "  W2_gradient, b2_gradient, flattened_gradient = backward_linear(\n",
        "                  W2, b2, flattened, logits_gradient)\n",
        "  \n",
        "  first_after_relu_gradient = flattened_gradient.reshape(first_after_relu.shape)\n",
        "  first_max_pool_gradient = backward_relu(\n",
        "                  first_max_pool, first_after_relu_gradient)\n",
        "  first_convolution_gradient = backward_max_pool(\n",
        "      first_convolution, MAX_POOL_SIZE, MAX_POOL_SIZE, first_max_pool_gradient)\n",
        "  \n",
        "  W1_gradient, b1_gradient, _ = backward_convolution(\n",
        "                  W1, b1, data, first_convolution_gradient) \n",
        "  return {\n",
        "      'W1': W1_gradient, \n",
        "      'b1': b1_gradient, \n",
        "      'W2': W2_gradient, \n",
        "      'b2': b2_gradient, \n",
        "      'y_gradient': y_gradient\n",
        "  }"
      ],
      "metadata": {
        "id": "IgGY_qx_Xrmv"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop_batch(batch_data, batch_labels, params, forward_prop_func):\n",
        "  \"\"\" Apply the forward-prop to every image in the batch set \"\"\" \n",
        "  y_array = []\n",
        "  cost_array = []\n",
        "  for item, label in zip(batch_data, batch_labels):\n",
        "    y, cost = forward_prop_func(item, label, params)\n",
        "    y_array.append(y)\n",
        "    cost_array.append(cost)\n",
        "  \n",
        "  return np.array(y_array), np.array(cost_array)"
      ],
      "metadata": {
        "id": "1-Hj4Qo3XruQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_batch(batch_data, batch_labels, learning_rate, \n",
        "                           params, backward_prop_func):\n",
        "  \"\"\" \n",
        "  Perform one batch of gradient descent on the given training data using 'lr'\n",
        "  It updates the parameters in the params \n",
        "  - batch-data a numpy containing the training data per batch \n",
        "  - train-labels a numpy array containing the training labels for the batch \n",
        "  - learning rate \n",
        "  - params - dictionary of params names to parameter values to be updated \n",
        "  - backward-prop-func to follows backward-prop API \n",
        "  \"\"\"\n",
        "  total_gradient = {}\n",
        "\n",
        "  for i in range(batch_data.shape[0]):\n",
        "    gradient = backward_prop_func(\n",
        "        batch_data[i, :, :], \n",
        "        batch_labels[i, :], \n",
        "        params) \n",
        "    for key, value in gradient.items():\n",
        "      if key not in total_gradient:\n",
        "        total_gradient[key] = np.zeros(value.shape)\n",
        "      total_gradient[key] += value \n",
        "  \n",
        "  params['W1'] = params['W1'] - learning_rate * total_gradient['W1']\n",
        "  params['W2'] = params['W2'] - learning_rate * total_gradient['W2']\n",
        "  params['b1'] = params['b1'] - learning_rate * total_gradient['b1']\n",
        "  params['b2'] = params['b2'] - learning_rate * total_gradient['b2']\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "Y0EI2P4RXrx1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network_train(\n",
        "  train_data, train_labels, dev_data, dev_labels, \n",
        "  get_initial_params_func, forward_prop_func, backward_prop_func,\n",
        "  learning_rate=5, batch_size=16, num_batches=400):\n",
        "  \"\"\"\n",
        "  Train model using gradient descent for specified number of epochs.\n",
        "  Evaluates loss and accuracy on training and dev set \n",
        "  -- at the end of each epoch --\n",
        "  train_data and train_labels: numpy arrays \n",
        "  \"\"\"\n",
        "  n = train_data.shape[0]\n",
        "  params = get_initial_params_func()\n",
        "\n",
        "  cost_train, cost_dev = [], []\n",
        "  accuracy_train, accuracy_dev = [], []\n",
        "  for batch in range(num_batches):\n",
        "    if batch % 10 == 0:\n",
        "      print('Currently processing {} / {} '.format(batch, num_batches))\n",
        "    batch_data = train_data[batch*batch_size: (batch +1)*batch_size, :, :, :]\n",
        "    batch_labels = train_labels[batch*batch_size: (batch +1)*batch_size, :] \n",
        "    if batch % 100 == 0:\n",
        "      output_d, cost_d = forward_prop_batch(\n",
        "          dev_data, dev_labels, params, forward_prop_func)\n",
        "      cost_dev.append(sum(cost_d) / len(cost_d))\n",
        "      accuracy_dev.append(compute_accuracy(output_d, dev_labels))\n",
        "\n",
        "      output_t, cost_t = forward_prop_batch(\n",
        "          train_data, train_labels, params, forward_prop_func)\n",
        "      cost_train.append(sum(cost_t) / len(cost_t))\n",
        "      accuracy_train.append(compute_accuracy(output_t, train_labels))\n",
        "      \n",
        "      print('Cost and accuracy', cost_dev[-1], accuracy_dev[-1])\n",
        "\n",
        "    gradient_descent_batch(\n",
        "        batch_data, batch_labels, learning_rate, params, backward_prop_func)\n",
        "  \n",
        "  return params, cost_train, cost_dev, accuracy_train, accuracy_dev \n"
      ],
      "metadata": {
        "id": "qYa_S6X3Xr1E"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network_test(data, labels, params):\n",
        "  output, cost = forward_prop(data, labels, params)\n",
        "  accuracy = compute_accuracy(output, labels)\n",
        "\n",
        "  return accuracy "
      ],
      "metadata": {
        "id": "yX_nstJJbAvX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(output, labels):\n",
        "  correct_output = np.argmax(output, axis=1)\n",
        "  correct_labels = np.argmax(labels, axis=1)\n",
        "  is_correct = [a == b for a, b in zip(correct_output, correct_labels)]\n",
        "  accuracy = sum(is_correct) * 1./labels.shape[0]\n",
        "\n",
        "  return accuracy "
      ],
      "metadata": {
        "id": "flKXJcqHXr46"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_labels(labels):\n",
        "  \"\"\" Convert labels from integers to one hot encoding \"\"\"\n",
        "  one_hot_labels = np.zeros((labels.size, 10))\n",
        "  one_hot_labels[np.arange(labels.size), labels.astype(int)] = 1\n",
        "  \n",
        "  return one_hot_labels "
      ],
      "metadata": {
        "id": "KZtRwGoSmg2K"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "_4Th2jiNm6ii",
        "outputId": "04367f04-23d4-433b-f3ea-6d0cbafb46ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d69d68e-7eaf-46cf-a412-404035dfd58c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d69d68e-7eaf-46cf-a412-404035dfd58c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving images_test.csv.gz to images_test.csv.gz\n",
            "Saving images_train.csv.gz to images_train.csv.gz\n",
            "Saving labels_test.csv.gz to labels_test.csv.gz\n",
            "Saving labels_train.csv.gz to labels_train.csv.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d images_test.csv.gz\n",
        "!gzip -d images_train.csv.gz\n",
        "!gzip -d labels_train.csv.gz\n",
        "!gzip -d labels_test.csv.gz"
      ],
      "metadata": {
        "id": "OaVF66H3m9km"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_from_file(images_file, labels_file):\n",
        "  \"\"\" load images and labels \"\"\" \n",
        "  x = np.loadtxt(images_file, delimiter=',')\n",
        "  y = np.loadtxt(labels_file, delimiter=',') \n",
        "  x = np.reshape(x, (x.shape[0], 1, 28, 28))\n",
        "  \n",
        "  return x, y"
      ],
      "metadata": {
        "id": "HCyCb0l7msEA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train(all_data, all_labels, backward_prop_func):\n",
        "  \n",
        "  params, cost_train, cost_dev, accuracy_train, accuracy_dev = \\\n",
        "      neural_network_train(\n",
        "          all_data['train'], all_labels['train'],\n",
        "          all_data['dev'], all_labels['dev'],\n",
        "          get_initial_params, forward_prop, backward_prop_func, \n",
        "          learning_rate=1e-2, batch_size=16, num_batches=400)\n",
        "  \n",
        "  t = np.arange(400 // 100)\n",
        "  fig_, (ax1, ax2) = plt.subplots(2, 1)\n",
        "\n",
        "  ax1.plot(t, cost_train, 'r', label='train')\n",
        "  ax1.plot(t, cost_dev, 'b', label='dev')\n",
        "  ax1.set_xlabel('time')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.set_title('Training curve')\n",
        "\n",
        "  ax2.plot(t, accuracy_train, 'r', label='train')\n",
        "  ax2.plot(t, accuracy_dev, 'b', label='dev')\n",
        "  ax2.set_xlabel('time')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  fig_.savefig('train.pdf')"
      ],
      "metadata": {
        "id": "SNPCHN76m7WB"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(100)\n",
        "train_data, train_labels = read_from_file('images_train.csv', 'labels_train.csv')\n",
        "train_labels = one_hot_labels(train_labels)\n",
        "perm = np.random.permutation(60000)\n",
        "train_data = train_data[perm, :]\n",
        "train_labels = train_labels[perm, :]\n",
        "\n",
        "dev_data = train_data[0:400, :]\n",
        "dev_labels = train_labels[0:400, :]\n",
        "train_data = train_data[400:, :]\n",
        "train_labels = train_labels[400:, :]\n",
        "\n",
        "mean = np.mean(train_data)\n",
        "std = np.std(train_data)\n",
        "train_data = (train_data - mean) / std \n",
        "dev_data = (dev_data - mean) / std \n",
        "\n",
        "all_data = {\n",
        "    'train': train_data, \n",
        "    'dev': dev_data}\n",
        "all_labels = {\n",
        "    'train': train_labels, \n",
        "    'dev': dev_labels}"
      ],
      "metadata": {
        "id": "miCcpG4NoxTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_train(all_data, all_labels, backward_prop) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "STf1TIP5sS5z",
        "outputId": "3567668c-1024-4f69-a77a-35f4ec9db7c7"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently processing 0 / 400 \n",
            "Cost and accuracy 2.721417647426753 0.0725\n",
            "Currently processing 10 / 400 \n",
            "Currently processing 20 / 400 \n",
            "Currently processing 30 / 400 \n",
            "Currently processing 40 / 400 \n",
            "Currently processing 50 / 400 \n",
            "Currently processing 60 / 400 \n",
            "Currently processing 70 / 400 \n",
            "Currently processing 80 / 400 \n",
            "Currently processing 90 / 400 \n",
            "Currently processing 100 / 400 \n",
            "Cost and accuracy 0.6413721697623074 0.78\n",
            "Currently processing 110 / 400 \n",
            "Currently processing 120 / 400 \n",
            "Currently processing 130 / 400 \n",
            "Currently processing 140 / 400 \n",
            "Currently processing 150 / 400 \n",
            "Currently processing 160 / 400 \n",
            "Currently processing 170 / 400 \n",
            "Currently processing 180 / 400 \n",
            "Currently processing 190 / 400 \n",
            "Currently processing 200 / 400 \n",
            "Cost and accuracy 0.43482822210982597 0.8625\n",
            "Currently processing 210 / 400 \n",
            "Currently processing 220 / 400 \n",
            "Currently processing 230 / 400 \n",
            "Currently processing 240 / 400 \n",
            "Currently processing 250 / 400 \n",
            "Currently processing 260 / 400 \n",
            "Currently processing 270 / 400 \n",
            "Currently processing 280 / 400 \n",
            "Currently processing 290 / 400 \n",
            "Currently processing 300 / 400 \n",
            "Cost and accuracy 0.3673995260534301 0.87\n",
            "Currently processing 310 / 400 \n",
            "Currently processing 320 / 400 \n",
            "Currently processing 330 / 400 \n",
            "Currently processing 340 / 400 \n",
            "Currently processing 350 / 400 \n",
            "Currently processing 360 / 400 \n",
            "Currently processing 370 / 400 \n",
            "Currently processing 380 / 400 \n",
            "Currently processing 390 / 400 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}